{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в теорию или как связаны подгузники и пиво?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Обучение на ассоциативных правилах (далее Assocoations rules learning - ARL) представляет из себя с одной стороны, простой, с другой - довольно часто применимый в реальной жизни метод поиска взаимосвязей (ассоциаций) в датасетах или, если точнее, айтемсетах (itemsests). Именно ARL лежит в основе многих рекомендательных систем, работающих в интернет-магазинах. \n",
    "   Впервые подробно об этом заговорил Piatesky-Shapiro G [1] в работе “Discovery, Analysis, and Presentation of Strong Rules.” (1991) Более подробо тему развивали Agrawal R, Imielinski T, Swami A в работах “Mining Association Rules between Sets of Items in Large Databases” (1993) [2] и “Fast Algorithms for Mining Association Rules.” (1994) [3].\n",
    "\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "  В общем виде ARL можно опсиать как \"Who bought x also bought y\" (\"Кто купил x, также купил y\"). В основе лежит анализ транзакций (transactions), внутри каждой из которых лежит свой уникальный itemset из набора items. При помощи ARL алогритмов нахоядтся те самые \"правила\" совпаденяи items внутри одной транзакции, котоыре потом сортируются по их силе. \n",
    "\n",
    "   Да, вот все так просто и логично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   За этой простотой, однако, могут скрываться поразительные вещи, о которых common sense даже не подозревал:) \n",
    "\n",
    "   Классический случай такого когнитивного диссонанса описан в статье D.J. Power \"Ask Dan!\", опубликованной в DSSResources.com [4]: \n",
    "\n",
    "   В 1992 году, группа по консалтингу в области ритейла компании Teradata под руководством Томаса Блишока провела исследование 1.2 миллиона транзакций в 25 магазинах для ритейлера Osco Drug (нет, там продавали не наркотики и даже не лекарства, точнее, не только лекартсва. Drug Store в стране веротяного противника - формат разнокалиберных магазинов у дома). \n",
    "   После анализа всех этих транзакций самым сильным правилом получилось \"Между 17:00 и 19:00 чаще всего пиво и подгузники покупают вместе\". \n",
    "   К сожалению такое правило показалось руководству Osco Drug настолкьо контринтуитивным, что ставить подгузники на полках рядом с пивом они не стали:) Хотя объяснение паре пиво-подгузники вполне себе нашлось: когда оба члена молодой семьи возвращались с рабоыт домой (как раз часам к 5 вечера), жены обычно отправляли мужей за подгузниками в ближайшей магазин. И мужья, не долго думая, совмещали приятное с полезным - покупали подгузники по заданию жены и пиво для собственного вечернего времяпрепровождения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание Association rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Итак мы выяснили, что пиво и подгузники - хороший джентельменский набор, а что дальше? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас имеется некий датасет (или коллекция) D, такой, что D = {d_0 ... d_j}, где d - уникальная транзакция-itemset (например, кассовый чек).\n",
    "Внутри каждой d представлен набор items (i - item), причем в идеально случае он представлен в бинарном виде: d1 = [{Пиво: 1}, {Вода: 0}, {Кола: 1}, {...}], d2 = [{Пиво : 0}, {Вода: 1}, {Кола : 1}, {...}]. Принято каждый itemset описывать через количество ненулевых значений (k-itemset), например, [{Пиво: 1}, {Вода: 0}, {Кола: 1}] являестя 2-itemset.\n",
    "\n",
    "Если в изначальном виде не представлен, можно при желании руками его преобразовать (OHE и pd.get_dummies вам в помощь).\n",
    "\n",
    "Таким образом, датасет представляет собой разреженную матрицу со значениями {1,0}. Это будет бинарный датасет. Существуют и другие виды записи - вертикальный датасет и транзакционный датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОК, данные преобразовали, как найти правила?\n",
    "\n",
    "Существует целый ряд ключевых (если хотите - базовых) понятий в ARL, которые нам помогут эти правила вывести."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support (поддержка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое понятие  в ARL - support:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$supp(X) = \\frac{\\{t\\in T;\\ X \\in t\\}}{|T|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", где X - itemset, содержащий в себе i-items, а T - количество транзакций. Т.е. в общем виде это показатель \"частотности\" данного itemset во всех анализируемых транзакциях. Но это касается только X. Нам же интересен скорее вариант, когда у нас в одном itemset встречаются x1 и x2 (например).\n",
    "Ну тут тоже все просто. Пусть x1 = {Пиво}, а x2 = {Подгузники}, значит нам нужно посчитать, во скольких транзакициях втречаестя эта парочка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$supp(x_1\\cup x_2) = \\frac{\\sigma(x_1 \\cup x_2)}{|T|}$, где $\\sigma $ - количество транзакций, содержащих $x_1$ и $x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confidence (уровень доверия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующее ключевое понятие - confidence. Это показатель того, как часто наше правило срабатывает для всего датасета. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$conf(x_1\\cup x_2) = \\frac{supp(x_1 \\cup x_2)}{supp(x_1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем пример: мы хотим посчитать confidence для правила \"кто покупает пиво, тот покупает и подгузники\".\n",
    "\n",
    "Для этого сначала посчитаем, какой support у правила \"покупает пиво\", потом посчитаем support у правила \"покупает пиво и подгузники\", и просто поделим одно на другое. Т.е. мы посчитаем в скольких случаях (транзакциях) срабатывает правило \"купил пиво $supp(X)$, купил подгузники и пиво $supp(X \\cup Y)$\"\n",
    "Ничего не напоминает? Байес смотрит на все это несколько недоуменно и с презрением:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/images/thomas-bayes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Lift (подъем или повышение)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующее понятие в нашем списке - lift. Грубо говоря, lift - это отношение \"зависимости\" items к их \"независимости\". Lift показывает, насколько items зависят друг от друга. Это очевидно из формулы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$lift(x_1\\cup x_2) = \\frac{supp(x_1 \\cup x_2)}{supp(x_1) \\times supp(x_2)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, мы хотим понять зависимость покупки пива и покупки подгузников. Для этого считаем support правила \"купил пиво и подгузники\" и делим его на произведение правил \"купил пиво\" и \"купил подгузники\". В случае, если lift = 1, мы говорим, что items независимы и правил совместной покупки тут нет. Если же lift > 1, то велечина, на которую lift, собственно, больше этой самой единицы, и покажет нам \"силу\" правила. Чем больше единицы, тем круче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conviction (убедительность)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем виде Conviction - это \"частотность ошибок\" нашего правила. Т.е., например, как часто покупали пиво без подгузников и наоборот."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$conv(x_1\\cup x_2) = \\frac{1 - supp(x_2)}{1 - conf(x_1 \\cup x_2)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем результат по формуле выше ближе к 1, тем лучше. Например, если conviction покупки пива и подгузников вместе равен 1.2, это значит, что правило \"купил пиво и подгузники\" было бы в 1.2 раза (на 20%) более верным, чем если бы совпадение этих items в одной транзакции было бы чисто случайным. Немного неинтуитивное понятие, но оно и используестя н етак часто, как предыдущие три. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <<<<<Отсутпление про брутфорс>>>>>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Используемые понятия:\n",
    "<br> -  Множество объектов (**itemset**): $X \\subseteq I = \\{x_1, x_2, ..., x_n\\}$</br>\n",
    "<br> -  Множество идентификаторов транзакций (**tidset**): $T = \\{t_1, t_2, ..., t_m\\}$</br>\n",
    "<br> -  Множество транзакций (**transactions**): $\\{(t,\\ X):\\ t\\in T,\\ X \\in I\\}$</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность brute-force алгоритма:\n",
    "Для того чтобы найти все возможные Association rules применяя brute-force алгоритм нам необходимо перечислить все подмножества $X$ из набора $I$ и для каждого подмножества $X$ рассчитать $supp(X)$. Данный подход будет состоять из следующих шагов:\n",
    "-  генерация **кандидатов**. Данный шаг состоит из перебора всех возможных подмножеств $X$ подмножества $I$. Данные подмножества называются **кандидатами**. Поскольку каждое подмножество теоретически может являться часто встречаемым подмножеством, то множество потенциальных кандидатов будет состоять из $2^{|I|}$ элементов (здесь $|I|$ обозначается число элементов множества $I$, а $2^{|I|}$ часто называется булеаном множества $I$, то есть множество всех подмножеств $I$)\n",
    "-  расчет **support**. На данном шаге рассчитывается $supp(X)$ каждого кандидата $X$\n",
    "\n",
    "Таким образом, сложность нашего алгоритма будет: $O(|I|*|D|*2^{|I|})$, где\n",
    "<br>$O(2^{|I|})$ - количество возможных кандидатов</br>\n",
    "<br>$O(|I|*|D|)$ - сложность расчета sup(X). Поскольку для расчета  $supp(X)$ нам необходимо перебрать все элементы в $I$ в каждой транзакции $t \\in T$</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем дополнительно еще несколько понятий.\n",
    "<br>Будем рассматривать дерево префиксов (prefix tree), где 2 элемента $X$ и $Y$ соединены, если $X$ является прямым подмножеством $Y$. Таким образом мы можем пронумеровать все подмножества множества $I$. Рисунок приведен ниже</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/src/images/tree_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, рассмотрим Apriori алгоритм.\n",
    "<br>\n",
    "Apriori алгоритм использует следующее утверждение: если $X \\subseteq Y$, то $supp(X) \\geq supp(Y)$. Откуда следуют следующие 2 свойства:\n",
    " -  если $Y$ встречается часто, то любое подмножество $X: X \\subseteq Y$  так же встречается часто\n",
    " -  если $X$ встречается редко, то любое супермножество $Y: Y \\supseteq X$ так же встречается редко\n",
    " </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriory алгоритм по-уровнево проходит по префиксному дереву и рассчитывает частоту встрчаемости подмножеств $X$ в $D$. Таким образом, в соответствии с алгоритмом:\n",
    " -  исключаются редкие подмножества и все их супемножества\n",
    " -  рассчитывается $supp(X)$ для кадого подходящего кандидата $X$ размера $k$ на уровне $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/src/images/tree_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn import... эммм... а импортировать-то и нечего:) На данный момент модулей для ALR в sklearn нет. Ну ничего, погуглим или напишем свои, правда?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "По сети гуляет целый ряд реализаций, например вот - https://github.com/asaini/Apriori, вот - http://adataanalyst.com/machine-learning/apriori-algorithm-python-3-0/, и даже вот -https://codereview.stackexchange.com/questions/38101/apriori-algorithm-using-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы же на практике придерживаемся алгоритма apyori, написанного Ю Мочиузки (Yu Mochizuki). Полный код приводить не будем, желающие могут посмотреть тут - https://github.com/ymoch/apyori , а вот архитектуру решения и пример использования покажем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условно решение Мочизуки можно разделить на 4 части: Структура данных, Внутренние функции, API и Прикладные функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая часть модуля (Структура данных) работает с изначальным датасетом. Реализуется класс TransactionManager, методы которого объединяют транзакции в матрицу, формируют список правил-кандидатов и считают support для каждого правила. Внутренние функции дополнительно по support'у формируют списки правил и соответственно их ранжируют. API логично позволяет работать напрямую с датасетами, а Прикладные функции позволяют обрабатывать транзакции и выводить результат в читаемый вид. Никакого rocketscience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как использовать модуль на реальном (ну, в данном случае - игрушечном) датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# подгрузим модули\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загрузим данные\n",
    "dataset = pd.read_csv('src/data/Market_Basket_Optimisation.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset.describe #всего 7500 записей-транзакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посомтрим на датасет\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что датасет у нас представляет разреженную матрицу, где в строках у нас набор items в каждой транзакции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#создаим из них матрицу\n",
    "transactions = []\n",
    "for i in range(0, 7501): \n",
    "    transactions.append([str(dataset.values[i,j]) for j in range(0, 20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#загружаем apriori\n",
    "import apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# и обучимся правилам. Обратите внимание, что пороговые значения мы вибираем сами в зависимости от того, /\n",
    "# насколкьо \"сильные\" правила мы хотим получит\n",
    "# min_support -- минимальный support для правил (dtype = float).\n",
    "# min_confidence -- минимальное значение confidence для правил (dtype = float)\n",
    "# min_lift -- минимальный lift (dtype = float)\n",
    "# max_length -- максимальная длина itemset (вспоминаем про k-itemset)  (dtype = integer)\n",
    "\n",
    "result = list(apriori(transactions, min_support = 0.003, min_confidence = 0.2, min_lift = 3, min_length = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# вот с визуализацией в пакете проблемы, точнее геморрой...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json #преобразовывать будем в json, используя встроенные в модуль методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for RelationRecord in result:\n",
    "    o = StringIO()\n",
    "    apyori.dump_as_json(RelationRecord, o)\n",
    "    output.append(json.loads(o.getvalue()))\n",
    "data_df = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# и взгялнем на итоги\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data_df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого мы видим:\n",
    "\n",
    "1. Пары items\n",
    "2. items_base - первый элемент пары\n",
    "3. items_add - второй (добавленный алгоритмом) элемент пары\n",
    "4. confidence - значение confidence для пары\n",
    "5. lift - значение lift для пары\n",
    "6. support - начение support для пары. При желании, по нему можно отсортировать \n",
    "\n",
    "\n",
    "Результаты логичные: эскалоп и макароны, эскалоп и сливочно-грибной соус, курица и нежирная сметана, мягкий сыр и мед и т.д. - все это вполне логичные и, главное, вкусные сочетания:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ARL тот случай,скогда R-фаги могут злорадно похихикать. В R реализована библиотека arules, где присутствует и apriori, и другие алгоритмы. Официальную доку можно посмотреть тут - https://cran.r-project.org/web/packages/arules/arules.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Посмотрим на нее в действии:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала установим ее (если еще не установили):\n",
    "<br>\n",
    "install.packages('arules')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные и преобразуем их в матрицу транзакций:\n",
    "<BR>\n",
    "<br>\n",
    "$library(arules)$\n",
    "<br>\n",
    "$dataset = read.csv('Market_Basket_Optimisation.csv', header = FALSE)$\n",
    "<br>\n",
    "$dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные:\n",
    "<BR>\n",
    "$summary(dataset)$\n",
    "<br>\n",
    "$itemFrequencyPlot(dataset, topN = 10)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выучим наши правила:\n",
    "<br>\n",
    "В общем виде фнкция вызова apriori выглядит так:  $apriori(data, parameter = NULL, appearance = NULL, control = NULL)$, где\n",
    "<br>\n",
    "\n",
    "$data$ - наш датасет\n",
    "<br>\n",
    "$paramter$ - список (list) параметров для модели: минимальные support, confidence и lift\n",
    "<br>\n",
    "$appearance$ - отвечает за отображение данных. Может принимать значения lhs, rhs, both, items, none, которые определяют положение items в output\n",
    "<br>\n",
    "$control$ - отвечает за сортировку вывода (ascending, descending, без сортировки), а также за то, отображать ли прогрессбар или нет (параметр verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$rules = apriori(data = dataset, parameter = list(support = 0.004, confidence = 0.2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посмотрим на результаты:\n",
    "<br>\n",
    "$inspect(sort(rules, by = 'lift')[1:10])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что на выходе имеем примерно те же результаты, что при использовании модуля apyori в Python:\n",
    "<br>\n",
    "\n",
    "1. {light cream}                               => {chicken}       0.004532729\n",
    "2. {pasta}                                     => {escalope}      0.005865885\n",
    "3. {pasta}                                     => {shrimp}        0.005065991\n",
    "4. {eggs,ground beef}                          => {herb & pepper} 0.004132782\n",
    "5. {whole wheat pasta}                         => {olive oil}     0.007998933\n",
    "6. {herb & pepper,spaghetti}                   => {ground beef}   0.006399147\n",
    "7. {herb & pepper,mineral water}               => {ground beef}   0.006665778\n",
    "8. {tomato sauce}                              => {ground beef}   0.005332622\n",
    "9. {mushroom cream sauce}                      => {escalope}      0.005732569\n",
    "10. {frozen vegetables,mineral water,spaghetti} => {ground beef}   0.004399413"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в R apriori использовать на данный момент намного удобнее, чем в Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECLAT Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Идея алгоритма ECLAT заключается в ускорении подсчета $supp(X)$. Для этого нам необходимо проиндексировать наше базу данных $D$ так, чтобы это позволило быстро рассчитывать $supp(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легко заметить, что если $t(X)$ обозначает множество всех транзакций, где встречается подмножество $X$, то\n",
    "<br>$t(XY) = t(X) \\cap t(Y)$</br>\n",
    "<br>и</br>\n",
    "<br>$supp(XY) = |t(XY)|$</br>\n",
    "<br> то есть $supp(XY)$ равен кардинальности (размеру) множества $t(XY)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/src/images/tree_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный подход может быть значительно усовершенствован путем уменьшения размера промежуточных множеств идентификаторов транзакций (tidsets). А именно, мы можем хранить не все множество транзакций на промежуточном уровне, а только множество различий этих транзакций. Предположим, что\n",
    "<br>$X_a = \\{x_1, x_2,..., x_{n-1}, a\\}$</br>\n",
    "<br>$X_b = \\{x_1, x_2,..., x_{n-1}, b\\}$</br>\n",
    "<br>Тогда, мы получим: </br>\n",
    "<br>$X_{ab} = \\{x_1, x_2,..., x_{n-1}, a, b\\}$</br>\n",
    "<br>$diffset(X_{ab})$ это множество всех id транзакций, которыесодержат префикс $X_a$ но не содержат элемент $b$: </br>\n",
    "<br>$d(X_{ab}) =t(X_a)/t(X_{ab})=t(X_a)/t(X_{b})$</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"/src/images/tree_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "И вновь пользователи R ликуют, для них никаких танцев с бубном делать не надо, все по аналогии с apriori. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Запускаем библиотеку и читаем данные:\n",
    "\n",
    "$library(arules)$\n",
    "<br>\n",
    "$dataset = read.csv('Market_Basket_Optimisation.csv')$\n",
    "<br>\n",
    "$dataset = read.transactions('Market_Basket_Optimisation.csv', sep = ',', rm.duplicates = TRUE)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Быстрый взгляд на датасет:\n",
    "<br>\n",
    "$summary(dataset)$\n",
    "<br>\n",
    "$itemFrequencyPlot(dataset, topN = 10)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правила:\n",
    "<br>\n",
    "$rules = eclat(data = dataset, parameter = list(support = 0.003, minlen = 2))$ \n",
    "<br>\n",
    "Обратите внимание, настраиваем толкьо support и минимальную длину (k в k-itemset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И смотрим на результаты:\n",
    "<br>\n",
    "$inspect(sort(rules, by = 'support')[1:10])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-Growth Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.fpm import FPGrowth\n",
    "# $example off$\n",
    "from pyspark import SparkContext\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sc = SparkContext(appName=\"FPGrowth\")\n",
    "\n",
    "    # $example on$\n",
    "    data = sc.textFile(\"src/data/sample_fpgrowth.txt\")\n",
    "    transactions = data.map(lambda line: line.strip().split(' '))\n",
    "    model = FPGrowth.train(transactions, minSupport=0.2, numPartitions=10)\n",
    "    result = model.freqItemsets().collect()\n",
    "    for fi in result:\n",
    "        print(fi)\n",
    "    # $example off$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
